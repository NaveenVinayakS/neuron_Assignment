{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58921a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpora:\n",
    "Corpora (plural of \"corpus\") are large collections of text documents used in linguistic analysis, natural language processing, and machine learning. Corpora can include text from various sources and are essential for training and testing language models. For example, the \"English Wikipedia\" can be considered a corpus.\n",
    "\n",
    "Tokens:\n",
    "Tokens are the individual units or elements that a text is divided into. In English, tokens are often words, but they can also be punctuation marks, numbers, or other meaningful elements. For instance, in the sentence \"I have 3 cats,\" the tokens are: [\"I\", \"have\", \"3\", \"cats\"].\n",
    "\n",
    "Unigrams, Bigrams, Trigrams:\n",
    "\n",
    "Unigrams: These are single words or tokens. For example, in the sentence \"I love ice cream,\" the unigrams are: [\"I\", \"love\", \"ice\", \"cream\"].\n",
    "Bigrams: These are sequences of two adjacent words. In the same sentence, the bigrams are: [\"I love\", \"love ice\", \"ice cream\"].\n",
    "Trigrams: These are sequences of three adjacent words. Continuing with the sentence, the trigrams are: [\"I love ice\", \"love ice cream\"].\n",
    "Generating n-grams from text:\n",
    "To generate n-grams from text, you can slide a window of n words across the text and extract the word sequences within the window. For example, with the sentence \"I love ice cream\" and n=2 (bigrams), you would slide the window as follows: \"I love\", \"love ice\", \"ice cream\".\n",
    "\n",
    "Lemmatization:\n",
    "Lemmatization is the process of reducing words to their base or dictionary form, called a lemma, to simplify analysis. For instance, the lemma of \"running\" is \"run,\" and the lemma of \"better\" is \"good.\"\n",
    "\n",
    "Stemming:\n",
    "Stemming is the process of removing suffixes from words to get their root form or stem. For example, stemming the word \"jumping\" would result in \"jump.\"\n",
    "\n",
    "Part-of-speech (POS) tagging:\n",
    "POS tagging is the process of labeling each word in a text with its grammatical part of speech, such as noun, verb, adjective, etc. For example, in the sentence \"She eats delicious pizza,\" POS tagging might label \"eats\" as a verb and \"delicious\" as an adjective.\n",
    "\n",
    "Chunking or shallow parsing:\n",
    "Chunking, also known as shallow parsing, involves grouping words in a sentence into chunks based on their grammatical relationships. It's often used to identify phrases like noun phrases (NP) or verb phrases (VP) in a sentence.\n",
    "\n",
    "Noun Phrase (NP) chunking:\n",
    "NP chunking is a type of chunking that focuses on identifying and grouping noun phrases in a sentence. In the sentence \"The big brown dog barked loudly,\" the NP chunks include \"The big brown dog\" and \"loudly.\"\n",
    "\n",
    "Named Entity Recognition (NER):\n",
    "NER is a process of identifying and categorizing named entities in text, such as names of people, places, organizations, dates, and more. In the sentence \"Apple Inc. was founded by Steve Jobs on April 1, 1976,\" NER would recognize \"Apple Inc.\" as an organization, \"Steve Jobs\" as a person, and \"April 1, 1976\" as a date.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
