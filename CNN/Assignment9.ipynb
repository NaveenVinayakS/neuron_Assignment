{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Advantages of CNN over DNN for Image Classification:\n",
    "Convolutional Neural Networks (CNNs) have several advantages over completely connected Deep Neural Networks (DNNs) for \n",
    "image classification:\n",
    "\n",
    "a. Parameter Sharing: CNNs use shared weights in convolutional layers, which reduces the number of parameters and allows \n",
    "    the network to learn spatial hierarchies efficiently.\n",
    "\n",
    "b. Translation Invariance: CNNs are capable of recognizing patterns irrespective of their location in the image, making \n",
    "    them suitable for image classification tasks.\n",
    "\n",
    "c. Feature Learning: CNNs automatically learn hierarchical features from raw pixel data, eliminating the need for \n",
    "    hand-crafted feature engineering.\n",
    "\n",
    "d. Reduced Overfitting: CNNs often exhibit improved generalization, as they learn local features that can be reused across\n",
    "    different parts of an image.\n",
    "\n",
    "e. Computation Efficiency: CNNs exploit local connectivity, enabling faster training and inference for image data compared \n",
    "    to fully connected DNNs.\n",
    "\n",
    "# 2. Calculations for CNN Layers:\n",
    "For a CNN with three convolutional layers, each with three kernels, a stride of two, and SAME padding, and input RGB images\n",
    "of size 200x300 pixels:\n",
    "\n",
    "Total Parameters: 6,100 parameters (100 in the first layer, 200 in the second, and 400 in the third).\n",
    "\n",
    "RAM Required for Single Instance Prediction (32-bit floats): 9.6 MB (6,100 parameters * 4 bytes/parameter).\n",
    "\n",
    "RAM Required for Batch of 50 Images: 480 MB (9.6 MB * 50 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Solutions for GPU Memory Shortage in CNN Training:\n",
    "If your GPU runs out of memory during CNN training, you can consider these solutions:\n",
    "\n",
    "a. Reduce Batch Size: Use a smaller batch size to reduce memory usage at the cost of longer training time.\n",
    "\n",
    "b. Lower Image Resolution: Resize input images to a smaller resolution.\n",
    "\n",
    "c. Simplify Model: Reduce the number of layers, filters, or neurons in your network.\n",
    "\n",
    "d. Use Mixed Precision: Utilize mixed-precision training to reduce memory usage.\n",
    "\n",
    "e. Gradient Accumulation: Accumulate gradients over mini-batches to simulate larger batch sizes.\n",
    "\n",
    "# 4. Max Pooling vs. Convolution with Same Stride:\n",
    "Max pooling is used in CNNs to downsample feature maps and introduce translation invariance. It commonly used with \n",
    "convolutional layers of the same stride because:\n",
    "\n",
    "Max pooling reduces the spatial dimensions, making the network computationally less intensive.\n",
    "It helps in selecting the most important information from the feature maps.\n",
    "It enhances translation invariance by considering the most significant features in each pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d29348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Local Response Normalization (LRN) Layer Use:\n",
    "A Local Response Normalization (LRN) layer can be useful when you want to apply lateral inhibition among neurons in a\n",
    "feature map. It can help in enhancing the contrast between different features and acts as a form of normalization. LRN is \n",
    "most beneficial when you want to encourage the network to focus on the strongest activations and suppress weaker ones.\n",
    "\n",
    "# 6. Innovations in CNN Architectures:\n",
    "\n",
    "AlexNet introduced the concept of deep convolutional neural networks with multiple layers, ReLU activations, and dropout, \n",
    "leading to improved performance.\n",
    "\n",
    "GoogLeNet introduced the inception module, which allowed for efficient network scaling with minimal computational cost. It\n",
    "used 1x1 convolutions to reduce computational complexity.\n",
    "\n",
    "ResNet introduced residual connections, enabling the training of very deep networks by mitigating the vanishing gradient\n",
    "problem. It made use of skip connections to learn residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d690ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Building a CNN for MNIST:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build the CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Using Inception v3 for Image Classification:\n",
    "To use Inception v3 for image classification, you can follow these steps:\n",
    "\n",
    "a. Load and preprocess images using libraries like matplotlib or scipy to ensure they have values ranging \n",
    "from -1.0 to 1.0.\n",
    "\n",
    "b. Resize and crop images to 299x299 pixels and convert them to RGB format.\n",
    "\n",
    "c. Load the Inception v3 model and fine-tune it for your specific classification task, replacing the output layer with the \n",
    "appropriate number of neurons for your classes and using softmax activation.\n",
    "\n",
    "d. Split your data into training and test sets for model evaluation.\n",
    "\n",
    "# 9. Large-Scale Image Recognition Using Transfer Learning:\n",
    "This task involves fine-tuning a pre-trained Inception v3 model for a new classification task. Here are the steps:\n",
    "\n",
    "a. Create a training dataset with at least 100 images per class.\n",
    "\n",
    "b. Preprocess the images, resizing, cropping, and adding data augmentation (e.g., random rotations, flips) to increase\n",
    "diversity in the dataset.\n",
    "\n",
    "c. Load the pre-trained Inception v3 model, freeze all layers up to the bottleneck layer, and replace the output layer \n",
    "with the appropriate number of neurons for your classes using softmax activation.\n",
    "\n",
    "d. Split the data into a training set and a test set to train and evaluate the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
